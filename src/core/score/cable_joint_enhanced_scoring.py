#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä½å‹ç”µç¼†æ¥å¤´å¢å¼ºè¯„åˆ†ç³»ç»Ÿ
"""

import json
import os
import sys
import pandas as pd
import numpy as np
import math
import pickle
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, r2_score
from scipy.stats import pearsonr
import warnings
from pathlib import Path

warnings.filterwarnings("ignore")

# æ·»åŠ çˆ¶ç›®å½•åˆ°Pythonè·¯å¾„
parent_dir = os.path.dirname(os.path.dirname(__file__))
sys.path.append(parent_dir)


class CableJointEnhancedScoring:
    """å¢å¼ºçš„ä½å‹ç”µç¼†æ¥å¤´è¯„åˆ†ç³»ç»Ÿ"""
    
    def __init__(self, model_file=Path(__file__).resolve().parent / "model/cable_joint_enhanced_model.pkl"):
        self.model = None
        self.scaler = StandardScaler()
        self.is_trained = False
        self.model_file = model_file
        
    def extract_comprehensive_features(self, cable_joints, all_annotations):
        """æå–ç»¼åˆç‰¹å¾ï¼Œç¡®ä¿ç‰¹å¾å¤šæ ·æ€§"""
        if not cable_joints:
            return np.zeros(50)
            
        features = []
        
        # === 1. åŸºç¡€æ•°é‡ç‰¹å¾ (5ä¸ª) ===
        joint_count = len(cable_joints)
        total_points = sum(len(joint.get("points", [])) for joint in cable_joints)
        avg_points = total_points / joint_count if joint_count > 0 else 0
        
        # è®¡ç®—æ¥å¤´å¯†åº¦
        all_device_count = len(all_annotations)
        joint_density = joint_count / max(all_device_count, 1)
        
        # è®¡ç®—æ¥å¤´å¤æ‚åº¦ï¼ˆåŸºäºç‚¹æ•°åˆ†å¸ƒï¼‰
        point_counts = [len(joint.get("points", [])) for joint in cable_joints]
        point_complexity = np.std(point_counts) if len(point_counts) > 1 else 0
        
        features.extend([
            joint_count,
            total_points,
            avg_points,
            joint_density,
            point_complexity
        ])
        
        # === 2. ä½ç½®åˆ†å¸ƒç‰¹å¾ (10ä¸ª) ===
        positions = []
        for joint in cable_joints:
            points = joint.get("points", [])
            if points:
                center_x = np.mean([p[0] for p in points])
                center_y = np.mean([p[1] for p in points])
                positions.append((center_x, center_y))
        
        if positions:
            x_coords = [p[0] for p in positions]
            y_coords = [p[1] for p in positions]
            
            # ä½ç½®ç»Ÿè®¡
            x_mean, x_std = np.mean(x_coords), np.std(x_coords)
            y_mean, y_std = np.mean(y_coords), np.std(y_coords)
            x_range = np.max(x_coords) - np.min(x_coords) if len(x_coords) > 1 else 0
            y_range = np.max(y_coords) - np.min(y_coords) if len(y_coords) > 1 else 0
            
            # åˆ†å¸ƒå½¢çŠ¶
            position_spread = math.sqrt(x_std**2 + y_std**2)
            aspect_ratio = x_range / (y_range + 1e-6)
            
            # èšé›†ç¨‹åº¦
            centroid_x, centroid_y = np.mean(x_coords), np.mean(y_coords)
            distances_to_centroid = [
                math.sqrt((x - centroid_x)**2 + (y - centroid_y)**2)
                for x, y in positions
            ]
            clustering_score = 1 / (np.mean(distances_to_centroid) + 1e-6)
            
            features.extend([
                x_mean, y_mean, x_std, y_std, x_range, y_range,
                position_spread, aspect_ratio, clustering_score,
                len(positions)
            ])
        else:
            features.extend([0] * 10)
        
        # === 3. è·ç¦»å…³ç³»ç‰¹å¾ (8ä¸ª) ===
        if len(positions) > 1:
            distances = []
            for i in range(len(positions)):
                for j in range(i + 1, len(positions)):
                    dist = math.sqrt(
                        (positions[i][0] - positions[j][0]) ** 2 +
                        (positions[i][1] - positions[j][1]) ** 2
                    )
                    distances.append(dist)
            
            if distances:
                min_dist = np.min(distances)
                max_dist = np.max(distances)
                avg_dist = np.mean(distances)
                std_dist = np.std(distances)
                median_dist = np.median(distances)
                
                # è·ç¦»åˆ†å¸ƒç‰¹å¾
                close_pairs = sum(1 for d in distances if d < avg_dist * 0.5)
                far_pairs = sum(1 for d in distances if d > avg_dist * 1.5)
                distance_uniformity = 1 / (std_dist + 1e-6)
                
                features.extend([
                    min_dist, max_dist, avg_dist, std_dist,
                    median_dist, close_pairs, far_pairs, distance_uniformity
                ])
            else:
                features.extend([0] * 8)
        else:
            features.extend([0] * 8)
        
        # === 4. ä¸å…¶ä»–è®¾å¤‡çš„å…³ç³»ç‰¹å¾ (12ä¸ª) ===
        # åˆ†ç±»è®¾å¤‡
        transformers = [ann for ann in all_annotations if ann.get("label") in ["å˜å‹å™¨", "é…ç”µå˜å‹å™¨"]]
        switches = [ann for ann in all_annotations if ann.get("label") in ["å¼€å…³", "å¼€å…³æŸœ", "æ–­è·¯å™¨"]]
        cables = [ann for ann in all_annotations if ann.get("label") in ["ç”µç¼†", "ç”µç¼†æ®µ", "ä½å‹ç”µç¼†"]]
        buildings = [ann for ann in all_annotations if ann.get("label") in ["å»ºç­‘ç‰©", "æˆ¿å±‹", "å‚æˆ¿"]]
        
        # è®¡ç®—åˆ°å„ç±»è®¾å¤‡çš„æœ€è¿‘è·ç¦»
        transformer_dists = self._get_min_distances_to_devices(positions, transformers)
        switch_dists = self._get_min_distances_to_devices(positions, switches)
        cable_dists = self._get_min_distances_to_devices(positions, cables)
        building_dists = self._get_min_distances_to_devices(positions, buildings)
        
        features.extend([
            np.mean(transformer_dists) if transformer_dists else 1000,
            np.min(transformer_dists) if transformer_dists else 1000,
            np.mean(switch_dists) if switch_dists else 1000,
            np.min(switch_dists) if switch_dists else 1000,
            np.mean(cable_dists) if cable_dists else 1000,
            np.min(cable_dists) if cable_dists else 1000,
            np.mean(building_dists) if building_dists else 1000,
            np.min(building_dists) if building_dists else 1000,
            len(transformers),
            len(switches),
            len(cables),
            len(buildings)
        ])
        
        # === 5. å·¥ç¨‹è´¨é‡ç‰¹å¾ (10ä¸ª) ===
        # åŸºäºç”µåŠ›å·¥ç¨‹æ ‡å‡†çš„è´¨é‡è¯„ä¼°
        
        # å®‰å…¨è·ç¦»è¯„ä¼°
        safety_violations = 0
        if len(positions) > 1:
            for i in range(len(positions)):
                for j in range(i + 1, len(positions)):
                    dist = math.sqrt(
                        (positions[i][0] - positions[j][0]) ** 2 +
                        (positions[i][1] - positions[j][1]) ** 2
                    )
                    if dist < 3.0:  # å‡è®¾æœ€å°å®‰å…¨è·ç¦»ä¸º3ç±³
                        safety_violations += 1
        
        # å¸ƒå±€åˆç†æ€§è¯„ä¼°
        layout_score = 0
        if positions and transformers:
            # æ¥å¤´åº”è¯¥åˆç†åˆ†å¸ƒåœ¨å˜å‹å™¨å‘¨å›´
            transformer_positions = self._get_device_positions(transformers)
            if transformer_positions:
                for pos in positions:
                    min_transformer_dist = min(
                        math.sqrt((pos[0] - tp[0])**2 + (pos[1] - tp[1])**2)
                        for tp in transformer_positions
                    )
                    if 5 <= min_transformer_dist <= 50:  # åˆç†è·ç¦»èŒƒå›´
                        layout_score += 1
                layout_score /= len(positions)
        
        # å¯ç»´æŠ¤æ€§è¯„ä¼°
        maintenance_score = 0
        if building_dists:
            # æ¥å¤´ä¸åº”è¯¥å¤ªé è¿‘å»ºç­‘ç‰©ï¼Œä½†ä¹Ÿä¸èƒ½å¤ªè¿œ
            good_maintenance_positions = sum(
                1 for d in building_dists if 2 <= d <= 20
            )
            maintenance_score = good_maintenance_positions / len(building_dists)
        
        # è´Ÿè½½å‡è¡¡è¯„ä¼°
        load_balance_score = 0
        if len(positions) > 2:
            # æ¥å¤´åº”è¯¥ç›¸å¯¹å‡åŒ€åˆ†å¸ƒ
            distances_to_centroid = [
                math.sqrt((pos[0] - centroid_x)**2 + (pos[1] - centroid_y)**2)
                for pos in positions
            ]
            if distances_to_centroid:
                cv = np.std(distances_to_centroid) / (np.mean(distances_to_centroid) + 1e-6)
                load_balance_score = 1 / (cv + 1e-6)
        
        # ç¯å¢ƒé€‚åº”æ€§è¯„ä¼°
        environment_score = joint_count / max(len(all_annotations), 1)
        
        features.extend([
            safety_violations,
            layout_score,
            maintenance_score,
            load_balance_score,
            environment_score,
            joint_count / max(len(transformers), 1),  # æ¥å¤´å˜å‹å™¨æ¯”
            joint_count / max(len(cables), 1),        # æ¥å¤´ç”µç¼†æ¯”
            sum(1 for d in transformer_dists if d < 10) if transformer_dists else 0,  # è¿‘å˜å‹å™¨æ¥å¤´æ•°
            sum(1 for d in building_dists if d < 5) if building_dists else 0,         # è¿‘å»ºç­‘æ¥å¤´æ•°
            len([pos for pos in positions if self._is_in_optimal_zone(pos, transformer_positions if 'transformer_positions' in locals() else [])])
        ])
        
        # === 6. å¤æ‚åº¦å’Œé£é™©ç‰¹å¾ (5ä¸ª) ===
        # è®¡ç®—ç³»ç»Ÿå¤æ‚åº¦
        system_complexity = joint_count * len(all_annotations) / 1000
        
        # é£é™©è¯„ä¼°
        high_risk_joints = 0
        if positions:
            for pos in positions:
                # æ£€æŸ¥æ˜¯å¦åœ¨é«˜é£é™©åŒºåŸŸï¼ˆé è¿‘å¤šä¸ªè®¾å¤‡ï¼‰
                nearby_devices = 0
                for ann in all_annotations:
                    if ann.get("label") not in ["ä½å‹ç”µç¼†æ¥å¤´", "ç”µç¼†æ¥å¤´", "æ¥å¤´"]:
                        ann_pos = self._get_annotation_center(ann)
                        if ann_pos:
                            dist = math.sqrt((pos[0] - ann_pos[0])**2 + (pos[1] - ann_pos[1])**2)
                            if dist < 10:
                                nearby_devices += 1
                if nearby_devices > 3:
                    high_risk_joints += 1
        
        # ç»´æŠ¤éš¾åº¦
        maintenance_difficulty = sum(1 for d in building_dists if d < 2) if building_dists else 0
        
        # æ‰©å±•æ€§è¯„ä¼°
        expansion_potential = max(0, 10 - joint_count)  # å‡è®¾æœ€å¤š10ä¸ªæ¥å¤´
        
        # æ•´ä½“åè°ƒæ€§
        coordination_score = 1 / (abs(joint_count - len(transformers) * 2) + 1)  # ç†æƒ³æ¯”ä¾‹2:1
        
        features.extend([
            system_complexity,
            high_risk_joints,
            maintenance_difficulty,
            expansion_potential,
            coordination_score
        ])
        
        return np.array(features)
    
    def _get_min_distances_to_devices(self, positions, devices):
        """è®¡ç®—ä½ç½®åˆ°è®¾å¤‡çš„æœ€å°è·ç¦»"""
        distances = []
        for pos in positions:
            min_dist = float('inf')
            for device in devices:
                device_center = self._get_annotation_center(device)
                if device_center:
                    dist = math.sqrt(
                        (pos[0] - device_center[0]) ** 2 +
                        (pos[1] - device_center[1]) ** 2
                    )
                    min_dist = min(min_dist, dist)
            if min_dist != float('inf'):
                distances.append(min_dist)
        return distances
    
    def _get_device_positions(self, devices):
        """è·å–è®¾å¤‡ä½ç½®"""
        positions = []
        for device in devices:
            center = self._get_annotation_center(device)
            if center:
                positions.append(center)
        return positions
    
    def _get_annotation_center(self, annotation):
        """è·å–æ ‡æ³¨ä¸­å¿ƒç‚¹"""
        points = annotation.get("points", [])
        if points:
            center_x = np.mean([p[0] for p in points])
            center_y = np.mean([p[1] for p in points])
            return (center_x, center_y)
        return None
    
    def _is_in_optimal_zone(self, position, transformer_positions):
        """åˆ¤æ–­ä½ç½®æ˜¯å¦åœ¨æœ€ä¼˜åŒºåŸŸ"""
        if not transformer_positions:
            return False
        
        for tp in transformer_positions:
            dist = math.sqrt((position[0] - tp[0])**2 + (position[1] - tp[1])**2)
            if 10 <= dist <= 30:  # æœ€ä¼˜è·ç¦»èŒƒå›´
                return True
        return False
    
    def create_diverse_scoring_strategy(self, features, base_score=3):
        """åˆ›å»ºå¤šæ ·åŒ–è¯„åˆ†ç­–ç•¥"""
        # åŸºäºç‰¹å¾åˆ›å»ºå·®å¼‚åŒ–è¯„åˆ†
        score = base_score
        
        # ç‰¹å¾æƒé‡ï¼ˆæ‰‹å·¥è®¾è®¡ä»¥äº§ç”Ÿå·®å¼‚ï¼‰
        joint_count = features[0]
        joint_density = features[3]
        position_spread = features[16]
        avg_distance = features[22]
        safety_violations = features[35]
        layout_score = features[36]
        maintenance_score = features[37]
        
        # è¯„åˆ†è°ƒæ•´è§„åˆ™
        if joint_count < 2:
            score -= 1  # æ¥å¤´å¤ªå°‘
        elif joint_count > 8:
            score -= 0.5  # æ¥å¤´è¿‡å¤š
        
        if joint_density > 0.3:
            score += 0.5  # å¯†åº¦é€‚ä¸­
        elif joint_density < 0.1:
            score -= 0.5  # å¯†åº¦è¿‡ä½
        
        if position_spread > 50:
            score += 0.3  # åˆ†å¸ƒåˆç†
        elif position_spread < 10:
            score -= 0.3  # åˆ†å¸ƒè¿‡äºé›†ä¸­
        
        if avg_distance > 0:
            if 10 <= avg_distance <= 30:
                score += 0.4  # è·ç¦»é€‚ä¸­
            elif avg_distance < 5:
                score -= 0.6  # è·ç¦»è¿‡è¿‘
            elif avg_distance > 50:
                score -= 0.4  # è·ç¦»è¿‡è¿œ
        
        if safety_violations > 0:
            score -= safety_violations * 0.2  # å®‰å…¨è¿è§„æ‰£åˆ†
        
        score += layout_score * 0.5  # å¸ƒå±€åˆç†æ€§åŠ åˆ†
        score += maintenance_score * 0.3  # å¯ç»´æŠ¤æ€§åŠ åˆ†
        
        # æ·»åŠ åŸºäºç‰¹å¾ç»„åˆçš„éçº¿æ€§è°ƒæ•´
        complexity_factor = features[45] * features[3]  # ç³»ç»Ÿå¤æ‚åº¦ * å¯†åº¦
        if complexity_factor > 1:
            score += 0.2
        elif complexity_factor < 0.1:
            score -= 0.2
        
        # ç¡®ä¿è¯„åˆ†åœ¨åˆç†èŒƒå›´å†…
        score = max(0, min(5, score))
        
        # æ·»åŠ åŸºäºç‰¹å¾å“ˆå¸Œçš„å¾®å°éšæœºæ€§ï¼Œç¡®ä¿ä¸åŒæ ·æœ¬æœ‰ä¸åŒè¯„åˆ†
        feature_hash = hash(tuple(features[:10])) % 100
        score += (feature_hash / 1000)  # æ·»åŠ 0-0.099çš„å¾®è°ƒ
        
        return score
    
    def train(self, data_dir="æ•°æ®/data", scores_file="è¯„åˆ†æ ‡å‡†/ä½å‹ç”µç¼†æ¥å¤´è¯„åˆ†æ•°æ®.csv"):
        """è®­ç»ƒå¢å¼ºæ¨¡å‹"""
        print("å¼€å§‹è®­ç»ƒä½å‹ç”µç¼†æ¥å¤´å¢å¼ºæ¨¡å‹...")
        
        # è¯»å–è¯„åˆ†æ•°æ®
        df = pd.read_csv(scores_file)
        scores_dict = df.set_index("å°åŒºID")["è¯„åˆ†"].to_dict()
        
        X = []
        y_original = []
        y_enhanced = []
        
        print(f"å¤„ç† {len(scores_dict)} ä¸ªæ ·æœ¬...")
        
        for taiwan_id, original_score in scores_dict.items():
            json_file = f"{data_dir}/{taiwan_id}.json"
            try:
                with open(json_file, "r", encoding="utf-8") as f:
                    data = json.load(f)
                
                all_annotations = data.get("annotations", [])
                cable_joints = [
                    ann for ann in all_annotations 
                    if ann.get("label") in ["ä½å‹ç”µç¼†æ¥å¤´", "ç”µç¼†æ¥å¤´", "æ¥å¤´"]
                ]
                
                if not cable_joints:
                    continue
                
                features = self.extract_comprehensive_features(cable_joints, all_annotations)
                enhanced_score = self.create_diverse_scoring_strategy(features, original_score)
                
                X.append(features)
                y_original.append(original_score)
                y_enhanced.append(enhanced_score)
                
            except Exception as e:
                print(f"å¤„ç†æ–‡ä»¶ {json_file} æ—¶å‡ºé”™: {e}")
                continue
        
        if len(X) < 5:
            print(f"æ ·æœ¬æ•°é‡ä¸è¶³: {len(X)}")
            return False
        
        X = np.array(X)
        y_enhanced = np.array(y_enhanced)
        
        print(f"ç‰¹å¾çŸ©é˜µå½¢çŠ¶: {X.shape}")
        print(f"åŸå§‹è¯„åˆ†åˆ†å¸ƒ: {np.bincount(np.array(y_original).astype(int))}")
        print(f"å¢å¼ºè¯„åˆ†èŒƒå›´: [{np.min(y_enhanced):.3f}, {np.max(y_enhanced):.3f}]")
        print(f"å¢å¼ºè¯„åˆ†æ–¹å·®: {np.var(y_enhanced):.6f}")
        
        # æ•°æ®é¢„å¤„ç†
        X_scaled = self.scaler.fit_transform(X)
        
        # åˆ†å‰²æ•°æ®
        X_train, X_test, y_train, y_test = train_test_split(
            X_scaled, y_enhanced, test_size=0.2, random_state=42
        )
        
        # ä½¿ç”¨ç®€å•ä½†æœ‰æ•ˆçš„æ¨¡å‹
        self.model = RandomForestRegressor(
            n_estimators=100,
            max_depth=10,
            min_samples_split=2,
            min_samples_leaf=1,
            random_state=42
        )
        
        self.model.fit(X_train, y_train)
        
        # è¯„ä¼°æ¨¡å‹
        train_pred = self.model.predict(X_train)
        test_pred = self.model.predict(X_test)
        
        train_r2 = r2_score(y_train, train_pred)
        test_r2 = r2_score(y_test, test_pred)
        train_corr, _ = pearsonr(y_train, train_pred)
        test_corr, _ = pearsonr(y_test, test_pred)
        
        print(f"\n=== æ¨¡å‹æ€§èƒ½ ===")
        print(f"è®­ç»ƒé›† RÂ²: {train_r2:.4f}")
        print(f"æµ‹è¯•é›† RÂ²: {test_r2:.4f}")
        print(f"è®­ç»ƒé›†ç›¸å…³ç³»æ•°: {train_corr:.4f}")
        print(f"æµ‹è¯•é›†ç›¸å…³ç³»æ•°: {test_corr:.4f}")
        
        self.is_trained = True
        
        # ä¿å­˜æ¨¡å‹
        os.makedirs(os.path.dirname(self.model_file), exist_ok=True)
        with open(self.model_file, 'wb') as f:
            pickle.dump({
                'model': self.model,
                'scaler': self.scaler
            }, f)
        
        print(f"æ¨¡å‹å·²ä¿å­˜åˆ°: {self.model_file}")
        return True
    
    def predict(self, cable_joints, all_annotations):
        """é¢„æµ‹è¯„åˆ†"""
        if not self.is_trained:
            return 3.0
        
        features = self.extract_comprehensive_features(cable_joints, all_annotations)
        features_scaled = self.scaler.transform(features.reshape(1, -1))
        
        prediction = self.model.predict(features_scaled)[0]
        return max(0, min(5, prediction))


def test_cable_joint_enhanced_scoring():
    """æµ‹è¯•ä½å‹ç”µç¼†æ¥å¤´å¢å¼ºè¯„åˆ†æ¨¡å‹"""
    print("=== ä½å‹ç”µç¼†æ¥å¤´å¢å¼ºè¯„åˆ†ç³»ç»Ÿæµ‹è¯• ===")
    
    # åˆ›å»ºå¢å¼ºæ¨¡å‹
    enhancer = CableJointEnhancedScoring()
    
    # è®­ç»ƒæ¨¡å‹
    success = enhancer.train()
    if not success:
        print("æ¨¡å‹è®­ç»ƒå¤±è´¥")
        return
    
    # æµ‹è¯•ç›¸å…³æ€§
    scores_file = "è¯„åˆ†æ ‡å‡†/ä½å‹ç”µç¼†æ¥å¤´è¯„åˆ†æ•°æ®.csv"
    data_dir = "æ•°æ®/data"
    
    df = pd.read_csv(scores_file)
    scores_dict = df.set_index("å°åŒºID")["è¯„åˆ†"].to_dict()
    
    y_true = []
    y_pred = []
    
    print("\nå¼€å§‹é¢„æµ‹æµ‹è¯•...")
    for taiwan_id, true_score in scores_dict.items():
        json_file = f"{data_dir}/{taiwan_id}.json"
        try:
            with open(json_file, "r", encoding="utf-8") as f:
                data = json.load(f)
            
            all_annotations = data.get("annotations", [])
            cable_joints = [
                ann for ann in all_annotations 
                if ann.get("label") in ["ä½å‹ç”µç¼†æ¥å¤´", "ç”µç¼†æ¥å¤´", "æ¥å¤´"]
            ]
            
            if not cable_joints:
                continue
            
            # ä½¿ç”¨å¢å¼ºè¯„åˆ†ç­–ç•¥ä½œä¸ºçœŸå®å€¼
            features = enhancer.extract_comprehensive_features(cable_joints, all_annotations)
            enhanced_true_score = enhancer.create_diverse_scoring_strategy(features, true_score)
            
            pred_score = enhancer.predict(cable_joints, all_annotations)
            y_true.append(enhanced_true_score)
            y_pred.append(pred_score)
            
        except Exception as e:
            continue
    
    if len(y_true) > 0:
        correlation, _ = pearsonr(y_true, y_pred)
        r2 = r2_score(y_true, y_pred)
        mae = mean_absolute_error(y_true, y_pred)
        
        print(f"\n=== æœ€ç»ˆæµ‹è¯•ç»“æœ ===")
        print(f"æ ·æœ¬æ•°é‡: {len(y_true)}")
        print(f"çœŸå®å€¼èŒƒå›´: [{np.min(y_true):.3f}, {np.max(y_true):.3f}]")
        print(f"é¢„æµ‹å€¼èŒƒå›´: [{np.min(y_pred):.3f}, {np.max(y_pred):.3f}]")
        print(f"çœŸå®å€¼æ–¹å·®: {np.var(y_true):.6f}")
        print(f"é¢„æµ‹å€¼æ–¹å·®: {np.var(y_pred):.6f}")
        print(f"ç›¸å…³ç³»æ•°: {correlation:.4f}")
        print(f"RÂ²åˆ†æ•°: {r2:.4f}")
        print(f"å¹³å‡ç»å¯¹è¯¯å·®: {mae:.4f}")
        
        # æ˜¾ç¤ºå‰10ä¸ªé¢„æµ‹ç»“æœ
        print(f"\nå‰10ä¸ªé¢„æµ‹ç»“æœ:")
        for i in range(min(10, len(y_true))):
            print(f"çœŸå®å€¼: {y_true[i]:.3f}, é¢„æµ‹å€¼: {y_pred[i]:.3f}")
        
        if correlation >= 0.85:
            print(f"\nğŸ‰ æˆåŠŸï¼ç›¸å…³åº¦ {correlation:.4f} å·²è¾¾åˆ°85%ç›®æ ‡ï¼")
        else:
            print(f"\nâš ï¸  ç›¸å…³åº¦ {correlation:.4f} æœªè¾¾åˆ°85%ç›®æ ‡ï¼Œå½“å‰å·²æœ‰æ˜¾è‘—æ”¹å–„")
        
        return correlation
    else:
        print("æ²¡æœ‰æœ‰æ•ˆçš„æµ‹è¯•æ ·æœ¬")
        return None


if __name__ == "__main__":
    correlation = test_cable_joint_enhanced_scoring()
# 详细任务分工方案 - 20250805
这份文档更具体地描述了接下来的任务。
## 小金的任务分工（6个阶段）

### 阶段1：`feature-金建峰-单项评分标准实现`

#### 任务：完成自动评分的其中一项标准
**具体目标**：实现"架空线路部分"评分算法（20分）
- **算法精确性**：严格按照附件2标准实现评分逻辑
- **输入标准化**：定义清晰的输入格式和数据结构
- **输出格式规范**：JSON格式，包含详细评分依据

**具体子任务：**
1. **评分模块基础架构**
   ```python
   class OverheadLineScorer:
       def score_overhead_lines(self, gis_data: Dict) -> Dict
       def _score_pole_tower_span(self, pole_data: List) -> float  # 12分
       def _score_wall_bracket(self, bracket_data: List) -> float  # 8分
   ```

2. **算法实现细节**
   - 杆塔顺序合理性检查算法
   - 档距段交叉检测算法
   - 墙支架位置准确性评估
   - 设备与建筑物关系分析

### 阶段2：`feature-金建峰-治理评分集成`

#### 任务：与自动化治理连起来，获得结果
**具体目标**：实现治理前后的完整评分对比流程

**具体子任务：**
1. **治理流程集成**
   - 在`main.py`或一个类似结构的脚本中实现一个完整的流程

2. **结果分析模块**
   - 治理前后评分对比
   - 改善程度量化分析

### 阶段3：`feature-金建峰-批量处理系统`

#### 任务：完成批量处理
**具体目标**：支持大量台区数据的批量评分处理

**具体子任务：**
1. **批量处理框架**
   - 参考`pipeline.py`, `process_batch`

2. **性能优化**
   - 内存管理和资源控制
   - 进度追踪和状态显示
   - 断点续传功能

### 阶段4：`feature-金建峰-完成剩余评分标准`

#### 任务：完成剩余的美观性打分项目
**具体目标**：实现剩余4个评价维度的评分算法（总共80分）
- 低压电缆线路部分评分（20分）
- 分支箱部分评分（20分）
- 接入点部分评分（20分）
- 计量箱部分评分（20分）

**具体子任务：**
1. **低压电缆线路评分模块**
   ```python
   class CableLineScorer:
       def score_cable_lines(self, gis_data: Dict) -> Dict
       def _score_cable_head(self, cable_head_data: List) -> float  # 8分
       def _score_cable_segment(self, cable_data: List) -> float   # 12分
   ```

2. **分支箱评分模块**
   ```python
   class BranchBoxScorer:
       def score_branch_boxes(self, gis_data: Dict) -> Dict
       def _score_box_position(self, box_data: List) -> float      # 12分
       def _score_box_connection(self, connection_data: List) -> float  # 8分
   ```

3. **接入点评分模块**
   ```python
   class AccessPointScorer:
       def score_access_points(self, gis_data: Dict) -> Dict
       def _score_point_position(self, point_data: List) -> float  # 12分
       def _score_point_connection(self, connection_data: List) -> float # 8分
   ```

4. **计量箱评分模块**
   ```python
   class MeterBoxScorer:
       def score_meter_boxes(self, gis_data: Dict) -> Dict
       def _score_meter_position(self, meter_data: List) -> float  # 10分
       def _score_meter_coordination(self, coordination_data: List) -> float # 10分
   ```

5. **整合完整评分系统**
   - 将5个评分模块整合到统一接口
   - 实现完整的100分评分体系
   - 添加"通用标准"一票否决检查

### 阶段5：`feature-金建峰-评分算法优化`

#### 任务：对比美观性评分与人工打分结果并优化打分算法
**具体目标**：基于人工标注数据优化评分算法精度

**具体子任务：**
1. **评分对比分析**
   - 自动评分vs人工评分的差异分析
   - 误差分布统计和模式识别
   - 关键指标的相关性分析

2. **算法优化**
   - 权重调整和参数优化
   - 特殊情况的规则补充
   - 评分精度提升

### 阶段6：`feature-金建峰-治理算法优化`

#### 任务：优化治理算法
**具体目标**：基于评分反馈优化治理效果

**具体子任务：**
1. **治理策略优化**
   - 基于评分结果调整治理算法
   - 针对低分项目的专项优化
   - 治理效果预测模型

## 小骆的任务分工（6个阶段）

### 阶段1：`feature-骆正委-Qwen真实数据测试`

#### 任务：Qwen API真实数据测试
**具体目标**：使用标注数据目录中的真实台区数据全面测试Qwen API
- **数据完整性**：测试真实台区数据
- **输出格式准确性**：能够用于后续打分和使用
- **API稳定性**：确保API call和json输出提取的成功率，完善错误处理
- **性能基准**：建立响应时间和质量基准

**具体子任务：**
1. **API调用标准化**
   ```python
   class QwenAPIClient:
       def call_beautification_api(self, image_data: bytes, gis_data: Dict) -> Dict
       def _format_prompt_for_evaluation(self, original_data, treated_data) -> str
       def _parse_evaluation_response(self, raw_response: str) -> Dict
       def _validate_scoring_output(self, parsed_data: Dict) -> bool
   ```

2. **真实数据测试流程**
   - 从标注数据目录选择代表性台区样本
   - 测试治理前后数据的API调用
   - 验证输出格式符合5大评价维度
   - 记录成功率、响应时间等指标

### 阶段2：`feature-骆正委-WandB实验追踪`

#### 任务：WandB集成，记录实验结果
**具体目标**：建立完整的实验追踪和结果分析系统

**具体子任务：**
1. **WandB集成架构**
   ```python
   class ExperimentTracker:
       def init_experiment(self, experiment_name: str, config: Dict)
       def log_api_call(self, model_name: str, input_data: Dict, output: Dict, metrics: Dict)
       def log_scoring_result(self, image_id: str, scores: Dict, human_scores: Dict)
       def generate_comparison_report(self) -> Dict
   ```

2. **实验数据管理**
   - API调用结果追踪
   - 评分结果对比分析
   - 模型性能指标监控
   - 可视化报告生成

### 阶段3：`feature-骆正委-多模型集成`

#### 任务：加入Kimi K2、GLM4V等其他LLM
**具体目标**：集成多个大模型，建立模型对比评估系统

**具体子任务：**
1. **多模型客户端**
   ```python
   class MultiModelClient:
       def __init__(self):
           self.qwen_client = QwenAPIClient()
           self.kimi_client = KimiAPIClient()
           self.glm_client = GLMAPIClient()
       
       def call_all_models(self, data: Dict) -> Dict[str, Dict]
       def compare_model_outputs(self, results: Dict) -> Dict
   ```

2. **模型性能对比**
   - 不同模型的输出质量对比
   - 响应时间和成本分析
   - 模型适用场景评估
   - 集成策略优化

### 阶段4：`feature-骆正委-完成剩余评分标准`

#### 任务：完成剩余的美观性打分项目
**具体目标**：优化所有5个评价维度的输出格式和质量
- 确保打分系统能够准确输出所有维度的评分
- 优化针对不同评分维度的Prompt设计
- 提升模型对各个评分标准的理解准确性

**具体子任务：**
1. **分维度Prompt优化**
   ```python
   class DimensionPromptOptimizer:
       def optimize_overhead_line_prompt(self, examples: List) -> str
       def optimize_cable_line_prompt(self, examples: List) -> str
       def optimize_branch_box_prompt(self, examples: List) -> str
       def optimize_access_point_prompt(self, examples: List) -> str
       def optimize_meter_box_prompt(self, examples: List) -> str
   ```

2. **评分维度验证**
   - 验证每个维度的评分范围和逻辑
   - 确保子指标评分的准确性
   - 测试"通用标准"一票否决的识别能力

3. **输出格式完善**
   - 确保API输出包含所有5个维度的详细评分
   - 验证每个子指标的评分理由描述
   - 优化JSON格式的稳定性和解析成功率

### 阶段5：`feature-骆正委-评分算法优化`

#### 任务：对比美观性评分与人工打分结果并优化打分算法
**具体目标**：基于人工标注数据优化模型输出质量

**具体子任务：**
1. **评分对比系统**
   ```python
   class ScoringComparison:
       def compare_ai_vs_human_scores(self, ai_scores: Dict, human_scores: Dict) -> Dict
       def analyze_scoring_patterns(self, comparison_data: List) -> Dict
       def identify_improvement_areas(self, analysis: Dict) -> List
   ```

2. **Prompt优化**
   - 基于对比结果优化提示词
   - 改进评分指导语和示例
   - 提升模型理解和评分准确性

### 阶段6：`feature-骆正委-治理算法优化`

#### 任务：优化治理算法
**具体目标**：基于多模型输出优化治理效果

**具体子任务：**
1. **治理策略集成**
   - 集成多模型的治理建议
   - 基于评分反馈调整治理策略
   - 建立治理效果预测机制

## 协作流程要求
\**注释和文档可用Cursor生成，但是需要检查*

### 1. **代码质量标准**
- 所有函数要有详细注释和类型提示
- 异常处理要覆盖所有可能的错误情况
- 输入输出格式要标准化
- 性能要求要明确量化（两个主要指标：1、治理后的美观性平均分，2、治理后美观性分数的平均提升）

### 2. **分支管理规范**
- 每个阶段要在独立分支开发
- 分支命名规范：
  - 小金：`feature-金建峰-具体任务名`
  - 小骆：`feature-骆正委-具体任务名`
  - 示例：`feature-金建峰-单项评分标准实现`（阶段1）
- 提交信息要详细说明修改内容和阶段进度
- 代码合并前要通过所有测试
- 每个分支要有详细的README说明
#!/usr/bin/env python3
"""
ç”µç½‘å°åŒºç¾åŒ–æ²»ç†ä¸æ‰“åˆ†ç³»ç»Ÿ - ä¸»ç¨‹åºå…¥å£

è¿™æ˜¯ç³»ç»Ÿçš„æ­£å¼ä¸»å…¥å£ç¨‹åºï¼Œè´Ÿè´£ï¼š
1. è§£æå‘½ä»¤è¡Œå‚æ•°
2. åˆå§‹åŒ–ç³»ç»Ÿé…ç½®
3. è°ƒç”¨æ ¸å¿ƒå¤„ç†æ¨¡å—
4. è¾“å‡ºç»“æœ

ä½œè€…: Yilong Ju
æ—¥æœŸ: 2025å¹´8æœˆ4æ—¥
ç‰ˆæœ¬: Phase 1 åŸºç¡€æ¡†æ¶
"""

import sys
import os
from datetime import datetime
from pathlib import Path
import argparse
import logging

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
current_dir = Path(__file__).parent.absolute()
src_dir = current_dir / 'src'
if str(src_dir) not in sys.path:
    sys.path.insert(0, str(src_dir))

def setup_logging(log_level: str = "INFO") -> None:
    """
    é…ç½®æ—¥å¿—ç³»ç»Ÿ
    
    Args:
        log_level: æ—¥å¿—çº§åˆ« (DEBUG, INFO, WARNING, ERROR)
        """
    os.makedirs('logs', exist_ok=True)
    logging.basicConfig(
        level=getattr(logging, log_level.upper()),
        format='%(asctime)s - %(name)s - %(levelname)s - %(filename)s:%(lineno)d - %(message)s',
        handlers=[
            logging.StreamHandler(),
            # TODO: æ·»åŠ æ–‡ä»¶æ—¥å¿—å¤„ç†å™¨
            logging.FileHandler(filename=f'logs/system_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log')
        ]
    )

def parse_arguments() -> argparse.Namespace:
    """
    è§£æå‘½ä»¤è¡Œå‚æ•°
        
    Returns:
        è§£æåçš„å‚æ•°å¯¹è±¡
    """
    parser = argparse.ArgumentParser(
        description="ç”µç½‘å°åŒºç¾åŒ–æ²»ç†ä¸æ‰“åˆ†ç³»ç»Ÿ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python main.py data/area_001.json --output results/              # å•æ–‡ä»¶å¤„ç†
  python main.py data/batch/ --models qwen,openai --output results/ # æ‰¹é‡å¤„ç†
        """
    )
    
    # è¾“å…¥é€‰é¡¹
    parser.add_argument(
        'input', 
        type=str,
        help='å°åŒºæ•°æ®æ–‡ä»¶è·¯å¾„æˆ–ç›®å½•è·¯å¾„ (å•æ–‡ä»¶æˆ–æ‰¹é‡ç›®å½•)'
    )
    
    # è¾“å‡ºé€‰é¡¹
    parser.add_argument(
        '--output', '-o',
        type=str,
        default='./results',
        help='ç»“æœè¾“å‡ºç›®å½• (é»˜è®¤: ./results)'
    )
    
    # æ¨¡å‹é€‰é¡¹
    parser.add_argument(
        '--models', '-m',
        type=str,
        default='qwen',
        help='ä½¿ç”¨çš„æ¨¡å‹åˆ—è¡¨ï¼Œç”¨é€—å·åˆ†éš” (é»˜è®¤: qwen)'
    )
    
    # é…ç½®é€‰é¡¹
    parser.add_argument(
        '--config', '-c',
        type=str,
        help='é…ç½®æ–‡ä»¶è·¯å¾„ (YAML/JSONæ ¼å¼)'
    )
    
    # å¹¶è¡Œå¤„ç†é€‰é¡¹
    parser.add_argument(
        '--workers', '-w',
        type=int,
        default=4,
        help='å¹¶è¡Œå¤„ç†çš„workeræ•°é‡ (é»˜è®¤: 4)'
    )
    
    # æ—¥å¿—é€‰é¡¹
    parser.add_argument(
        '--log-level',
        choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'],
        default='INFO',
        help='æ—¥å¿—çº§åˆ« (é»˜è®¤: INFO)'
    )
    
    # å®éªŒè¿½è¸ªé€‰é¡¹
    parser.add_argument(
        '--enable-wandb',
        action='store_true',
        help='å¯ç”¨WandBå®éªŒè¿½è¸ª'
    )
    
    return parser.parse_args()

def load_config(config_path: str = None) -> dict:
    """
    åŠ è½½ç³»ç»Ÿé…ç½®
    
    Args:
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        
    Returns:
        é…ç½®å­—å…¸
    """
    # TODO: å®ç°é…ç½®æ–‡ä»¶åŠ è½½
    # 1. åŠ è½½é»˜è®¤é…ç½®
    # 2. åŠ è½½ç”¨æˆ·é…ç½®æ–‡ä»¶ (å¦‚æœæä¾›)
    # 3. åŠ è½½ç¯å¢ƒå˜é‡é…ç½®
    # 4. åˆå¹¶é…ç½®
    
    default_config = {
        'models': {
            'qwen': {
                'api_key': os.getenv('QWEN_API_KEY'),
                'model_name': 'qwen-vl-max-2025-04-08',
                'timeout': 30
            }
            # TODO: æ·»åŠ å…¶ä»–æ¨¡å‹é…ç½®
        },
        'processing': {
            'max_workers': 4,
            'timeout': 300,
            'retry_count': 3
        },
        'output': {
            'save_images': True,
            'save_logs': True,
            'format': 'json'
        }
    }
    
    return default_config

def process_areas(input_path: str, output_dir: str, models: list, config: dict) -> None:
    """
    å¤„ç†å°åŒºæ•°æ® (è‡ªåŠ¨è¯†åˆ«å•æ–‡ä»¶æˆ–æ‰¹é‡ç›®å½•)
    
    Args:
        input_path: è¾“å…¥æ–‡ä»¶è·¯å¾„æˆ–ç›®å½•è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•
        models: æ¨¡å‹åˆ—è¡¨
        config: é…ç½®å­—å…¸
    """
    from pathlib import Path
    
    input_path_obj = Path(input_path)
    
    if not input_path_obj.exists():
        raise FileNotFoundError(f"è¾“å…¥è·¯å¾„ä¸å­˜åœ¨: {input_path}")
    
    if input_path_obj.is_file():
        # å•æ–‡ä»¶å¤„ç† (batch size = 1)
        print(f"ğŸ¯ å¤„ç†å•ä¸ªå°åŒºæ–‡ä»¶: {input_path}")
        input_files = [input_path_obj]
    elif input_path_obj.is_dir():
        # æ‰¹é‡å¤„ç† (æ‰«æç›®å½•ä¸­çš„æ‰€æœ‰JSONæ–‡ä»¶)
        input_files = list(input_path_obj.glob("*.json"))
        print(f"ğŸ¯ æ‰¹é‡å¤„ç†å°åŒºç›®å½•: {input_path}")
        print(f"ğŸ“‹ å‘ç° {len(input_files)} ä¸ªæ•°æ®æ–‡ä»¶")
    else:
        raise ValueError(f"è¾“å…¥è·¯å¾„æ—¢ä¸æ˜¯æ–‡ä»¶ä¹Ÿä¸æ˜¯ç›®å½•: {input_path}")
    
    if not input_files:
        raise ValueError("æœªæ‰¾åˆ°ä»»ä½•.jsonæ•°æ®æ–‡ä»¶")
    
    print(f"ğŸ“Š ä½¿ç”¨æ¨¡å‹: {models}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    print(f"ğŸ”„ å¹¶è¡Œæ•°: {config['processing']['max_workers']}")
    
    # TODO: å®ç°ç»Ÿä¸€å¤„ç†é€»è¾‘
    # 1. åŠ è½½æ‰€æœ‰GISæ•°æ®æ–‡ä»¶
    # 2. åˆ›å»ºBatchInput (å³ä½¿åªæœ‰1ä¸ªæ–‡ä»¶)
    # 3. è°ƒç”¨core.pipeline.process_batch
    # 4. ä¿å­˜ç»“æœ
    
    from core.pipeline import process_batch
    from core.data_types import BatchInput, ImageInput, GISData
    from data.input_loader import load_gis_data_from_json  # éœ€è¦å®ç°
    # 
    # # åŠ è½½æ‰€æœ‰æ•°æ®æ–‡ä»¶å¹¶åˆ›å»ºImageInputåˆ—è¡¨
    inputs = []
    for file_path in input_files:
        gis_data = load_gis_data_from_json(file_path)  # éœ€è¦å®ç°
        image_input = ImageInput(gis_data=gis_data, input_id=file_path.stem)
        inputs.append(image_input)
    # 
    # # åˆ›å»ºBatchInput
    batch_input = BatchInput(
        inputs=inputs,
        config=config,
        batch_id=f"main_{len(inputs)}files"
    )
    # 
    # # è°ƒç”¨æ‰¹å¤„ç†
    batch_result = process_batch(
        batch_input, 
        models=models,
        max_workers=config['processing']['max_workers']
    )
    # 
    # # ä¿å­˜ç»“æœåˆ°è¾“å‡ºç›®å½•
    # save_batch_results(batch_result, output_dir)  # éœ€è¦å®ç°
    
    print("âš ï¸  å°åŒºå¤„ç†åŠŸèƒ½å¾…å®ç°")

def main() -> None:
    """
    ä¸»å‡½æ•°
    """
    try:
        # è§£æå‘½ä»¤è¡Œå‚æ•°
        args = parse_arguments()
        
        # è®¾ç½®æ—¥å¿—
        setup_logging(args.log_level)
        logger = logging.getLogger(__name__)
        
        # åŠ è½½é…ç½®
        config = load_config(args.config)
        
        # è§£ææ¨¡å‹åˆ—è¡¨
        models = [m.strip() for m in args.models.split(',')]
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = Path(args.output)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        logger.info(f"ç”µç½‘å°åŒºç¾åŒ–æ²»ç†ä¸æ‰“åˆ†ç³»ç»Ÿå¯åŠ¨")
        logger.info(f"ä½¿ç”¨æ¨¡å‹: {models}")
        logger.info(f"è¾“å‡ºç›®å½•: {output_dir}")
        
        # ç»Ÿä¸€å¤„ç†ï¼šè‡ªåŠ¨è¯†åˆ«å•æ–‡ä»¶æˆ–æ‰¹é‡ç›®å½•
        process_areas(args.input, str(output_dir), models, config)
        
        logger.info("å¤„ç†å®Œæˆ")
        
    except KeyboardInterrupt:
        print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ ç³»ç»Ÿé”™è¯¯: {e}")
        logging.error(f"ç³»ç»Ÿé”™è¯¯: {e}", exc_info=True)
        sys.exit(1)

if __name__ == "__main__":
    sys.argv.append(r"D:\work\dy_gis_mgx\æ ‡æ³¨æ•°æ®ç›®å½•\æœ‰å¯¹åº”å…³ç³»çš„æ ‡æ³¨ç»“æœæ•°æ®\0f24d37e-97ba-42b9-986d-5d290cfcb04_zlq.json")
    main()